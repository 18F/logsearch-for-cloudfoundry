
properties:
  <<: (( merge ))
  logstash_parser:
    <<: (( merge ))
    filters: "# All logs start being sent to the unparsed index.  \n# The filters below will route them to the @index=app or @index=platform\nmutate {\n    add_field => { \"[@metadata][index]\" => \"unparsed\" }\n    add_field => { \"[@metadata][type]\" => \"%{[@type]}\" }\n    remove_field => \"@type\" \n}\n\nif [@metadata][type] in [\"syslog\", \"relp\"] and [syslog_program] == \"doppler\" {\n# Parse Cloud Foundry logs from doppler (via https://github.com/SpringerPE/firehose-to-syslog)\n\njson {\n    source => 'syslog_message'\n    add_tag => [ 'cloudfoundry_doppler' ] #This is only added if json parsing is successful\n}\n\nif \"_jsonparsefailure\" in [tags] {\n\n    # Amend the failure tag to match our fail/${addon}/${filter}/${detail} standard\n    mutate {\n        add_tag => [\"fail/cloudfoundry/doppler/jsonparsefailure_of_syslog_message\"]\n        remove_tag => [\"_jsonparsefailure\"]\n    }\n\n} else {\n\n    date {\n        match => [ \"time\", \"ISO8601\" ]\n    }\n\n    # Replace the unicode newline character \\u2028 with \\n, which Kibana will display as a new line.  Seems that passing a string with an actual newline in it is the only way to make gsub work\n    mutate {\n      gsub => [ \"msg\", '\\u2028', \"\n\"\n      ]\n    }\n\n    if ('RTR' in [source_type]) {\n        grok {\n            #cf-release > v205 - includes RequestBytesReceived\n            match => { 'msg' => '%{HOSTNAME:hostname} - \\[(?<time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\\] \\\"%{WORD:verb} %{URIPATHPARAM:path} %{PROG:http_spec}\\\" %{BASE10NUM:status:int} %{BASE10NUM:request_bytes_received:int} %{BASE10NUM:body_bytes_sent:int} \\\"%{GREEDYDATA:referer}\\\" \\\"%{GREEDYDATA:http_user_agent}\\\" %{HOSTPORT} x_forwarded_for:\\\"%{GREEDYDATA:x_forwarded_for}\\\" vcap_request_id:%{NOTSPACE:vcap_request_id} response_time:%{NUMBER:response_time:float} app_id:%{NOTSPACE}' }\n\n            #cf-release <= v205\n\t    match => { 'msg' => '%{HOSTNAME:hostname} - \\[(?<time>%{MONTHDAY}/%{MONTHNUM}/%{YEAR}:%{TIME} %{INT})\\] \\\"%{WORD:verb} %{URIPATHPARAM:path} %{PROG:http_spec}\\\" %{BASE10NUM:status:int} %{BASE10NUM:body_bytes_sent:int} \\\"%{GREEDYDATA:referer}\\\" \\\"%{GREEDYDATA:http_user_agent}\\\" %{HOSTPORT} x_forwarded_for:\\\"%{GREEDYDATA:x_forwarded_for}\\\" vcap_request_id:%{NOTSPACE:vcap_request_id} response_time:%{NUMBER:response_time:float} app_id:%{NOTSPACE}' }\n\t    overwrite => [ \"time\" ]\n\t    tag_on_failure => [ 'fail/cloudfoundry/doppler/RTR' ]\n        }\n\n        if !(\"fail/cloudfoundry/doppler/RTR\" in [tags]) {\n            date {\n                match => [ \"time\", \"dd/MM/y:HH:mm:ss Z\" ]\n            }\n            if [x_forwarded_for] {\n                mutate {\n                    gsub => [\"x_forwarded_for\",\"[\\s\\\\\"]\",\"\"] # remove quotes and whitespace\n                    split => [\"x_forwarded_for\", \",\"] # format is client, proxy1, proxy2 ...\n                }\n\n               mutate {\n                  add_field => [\"remote_addr\", \"%{x_forwarded_for[0]}\"]\n               }\n\n               if ([remote_addr] =~ /([0-9]{1,3}\\.){3}[0-9]{1,3}/) {\n                   geoip {\n                     source => \"remote_addr\"\n                   }\n               }\n            }\n\n            mutate {\n                remove_field => [ \"msg\" ]\n            }\n        }\n    }\n\n    #Ensure that we always have an event_type, in prep for adding metrics\n    if ![event_type] {\n        mutate {\n            add_field => [ \"event_type\", \"LogMessage\" ]\n        }\n    }\n\n    mutate {\n        rename => [ \"syslog_message\", \"@message\" ]\n        remove_field => \"time\"\n        remove_field => \"syslog_severity_code\"\n        remove_field => \"syslog_facility_code\"\n        remove_field => \"syslog_facility\"\n        remove_field => \"syslog_severity\"\n        remove_field => \"syslog_pri\"\n        remove_field => \"syslog_program\"\n        remove_field => \"syslog_pid\"\n    }\n\n\n    mutate {\n        replace => { \"[@metadata][index]\" => \"app\" }\n        replace => { \"[@metadata][type]\" => \"cloudfoundry_doppler\" }\n    }\n\n}\n\n  if \"cloudfoundry_doppler\" in [tags] {\n    # Parse messages from /v2/events api logged by https://github.com/stayup-io/cf-app-events-logger \n\nif [msg] =~ /.*\"event_type\":\"AppEvent\".*/  {\n\n    json {\n        source => \"msg\"\n        target => \"app_event\"\n        add_tag => \"app_event\"\n    }\n\n    mutate {\n        rename => { \"[@metadata][type]\" => \"app_event\" }\n    }\n\n}\n\n\n  }\n} else if [@metadata][type] in [\"syslog\", \"relp\"] and [@source.host] == \"loggregator\" {\n# Parse Cloud Foundry logs from loggregator (syslog)\n# see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156\n\nmutate {\n    add_field => [ \"tmp_syslog_procid\" ,\"%{syslog_procid}\" ]\n}\n\n# [App/0] => [App, 0]\nmutate {\n    gsub => [ \"tmp_syslog_procid\", \"[\\[\\]]\", \"\" ]\n    split => [ \"tmp_syslog_procid\", \"/\" ]\n    add_field => [ \"source_type\" ,\"%{[tmp_syslog_procid][0]}\"  ]\n    add_field => [ \"source_instance\" ,\"%{[tmp_syslog_procid][1]}\"  ]\n    remove_field => [ \"tmp_syslog_procid\" ]\n}\n\n# For source types with no instance number, remove the field\nif [source_instance] == \"%{[tmp_syslog_procid][1]}\" {\n    mutate {\n      remove_field => [ \"source_instance\" ]\n    }\n}\n\n#If it looks like JSON, it must be JSON...\nif [syslog_message] =~ /^\\s*{\".*}\\s*$/ {\n    json {\n        source => \"syslog_message\"\n    }\n     # @todo seems like some messages have @timestamp in them? seems ci-specific\n    date {\n        match => [ \"@timestamp\", \"ISO8601\" ]\n    }\n} else {\n    mutate {\n        add_field => [ \"message\", \"%{syslog_message}\" ]\n    }\n    if [message] == \"-\" {\n        mutate {\n            remove_field => \"message\"\n        }\n    }\n}\n mutate {\n    rename => [ \"syslog_program\", \"@source.app_id\" ]\n}\n mutate {\n    add_tag => \"cloudfoundry_loggregator\"\n    remove_field => \"syslog_facility\"\n    remove_field => \"syslog_facility_code\"\n    remove_field => \"syslog_message\"\n    remove_field => \"syslog_severity\"\n    remove_field => \"syslog_severity_code\"\n    remove_field => \"syslog5424_ver\"\n    remove_field => \"syslog6587_msglen\"\n}\n\n} else if [@metadata][type] in [\"syslog\", \"relp\"] and [syslog_program] == \"vcap.uaa\" {\ngrok {\n    match => { \"syslog_message\" => \"\\[job=%{NOTSPACE:jobname}%{SPACE}index=%{NOTSPACE:jobindex}\\]%{SPACE}\\[%{TIMESTAMP_ISO8601:uaa_timestamp}\\]%{SPACE}uaa%{SPACE}-%{SPACE}%{NUMBER:pid:int}%{SPACE}\\[%{DATA:thread_name}\\]%{SPACE}....%{SPACE}%{LOGLEVEL:@loglevel}%{SPACE}---%{SPACE}Audit:%{SPACE}%{WORD:audit_event_type}%{SPACE}\\('%{DATA:audit_event_data}'\\):%{SPACE}principal=%{DATA:audit_event_principal},%{SPACE}origin=\\[%{DATA:audit_event_origin}\\],%{SPACE}identityZoneId=\\[%{DATA:audit_event_identity_zone_id}\\]\" }\n    tag_on_failure => [\n        \"fail/cloudfoundry/uaa-audit\"\n    ]\n    add_tag => \"uaa-audit\"\n}\n\nif !(\"fail/cloudfoundry/uaa-audit\" in [tags]) {\n    date {\n        match => [ \"uaa_timestamp\", \"ISO8601\" ]\n        remove_field => \"uaa_timestamp\"\n    }\n\n    if \"PrincipalAuthenticationFailure\" == [audit_event_type] {\n        mutate {\n            add_field => { \"audit_event_remote_address\" => \"%{audit_event_origin}\" }\n       }\n    }\n\n    if [audit_event_origin] =~ /remoteAddress=/ {\n        grok {\n            match => { \"audit_event_origin\" => \"remoteAddress=%{IP:audit_event_remote_address}\" }\n        }\n    }\n\n    if [audit_event_remote_address] {\n       geoip {\n          source => \"audit_event_remote_address\"\n       }\n    }\n\n    mutate {\n        remove_field => \"syslog_pri\"\n        remove_field => \"syslog_facility\"\n        remove_field => \"syslog_facility_code\"\n        remove_field => \"syslog_message\"\n        remove_field => \"syslog_severity\"\n        remove_field => \"syslog_severity_code\"\n\n        rename => { \"syslog_program\" => \"[@source][syslog_program]\" }\n        rename => { \"@source.host\"   => \"[@source][host]\" }\n        rename => { \"jobname\"        => \"[@source][job][name]\" }\n        rename => { \"jobindex\"       => \"[@source][job][index]\" }\n\n        split =>  { \"audit_event_origin\" => \", \" }\n    }\n\n    mutate {\n       #replace => { \"[@metadata][index]\" => \"platform\" }\n        replace => { \"[@metadata][type]\" => \"uaa-audit\" }\n     }\n}\n\n} else if \"collector\" in [tags] {\n# Parse Cloud Foundry Collector\n\nmutate {\n    add_field => { \"[@source][component]\" => \"%{[attributes][job]}\" }\n    add_field => { \"[@source][instance]\" => \"%{[attributes][index]}\" }\n    add_field => { \"[@source][deployment]\" => \"%{[attributes][deployment]}\" }\n    add_field => { \"[@source][host]\" => \"%{[attributes][ip]}\" }\n    remove_field => [ \"[attributes]\" ]\n}\n\nmutate {\n    add_field => { \"[@source][name]\" => \"%{[@source][component]}/%{[@source][instance]}\" }\n}\n\nmutate {\n    rename => { \"[key]\" => \"[metric][key]\" }\n}\n\nif [value] =~ \".\" {\n    mutate { \n        rename => { \"[value]\" => \"[metric][value_float]\" }\n        convert => { \"[metric][value_float]\" => \"float\" }\n    }\n} else {\n    mutate { \n        rename => { \"[value]\" => \"[metric][value_int]\" }\n        convert => { \"[metric][value_int]\" => \"integer\" }\n    }\n}\n\nmutate {\n    remove_field => [ \"level\", \"facility\", \"file\", \"line\", \"version\", \"source_host\", \"host\" ]\n}\n\n#Route to index and type\nmutate {\n    replace => { \"[@metadata][index]\" => \"platform\" }\n    replace => { \"[@metadata][type]\" => \"metric\" }\n    add_tag => \"metric\"\n}\n\n} else if [@metadata][type] in [\"syslog\", \"relp\"] and [syslog_program] =~ /vcap\\..*/ {\n# Parse Cloud Foundry logs from syslog_aggregator\n\ngrok {\n    match => { \"syslog_message\" => \"(?:\\[job=%{NOTSPACE:[@job][name]}|-) +(?:index=%{NOTSPACE:[@job][index]}\\]|-) %{GREEDYDATA:_message_json}\" }\n    tag_on_failure => [\n        \"_grokparsefailure-cf-vcap\"\n    ]\n}\n\nif !(\"_grokparsefailure-cf-vcap\" in [tags]) {\n    kv {\n        source => \"msgdata\"\n        field_split => \" \"\n        target => \"msgdata\"\n    }\n\n    json {\n        source => \"_message_json\"\n        remove_field => \"_message_json\"\n    }\n\n    mutate {\n        rename => [ \"syslog_program\", \"[@shipper][name]\" ]\n        replace => [ \"[@job][host]\", \"%{[@source][host]}\" ]\n        gsub => [\n            \"[@shipper][name]\", \"\\.\", \"_\",\n            \"[@job][name]\", \"\\.\", \"_\"\n          ]\n    }\n\n    if [source] == \"NatsStreamForwarder\" {\n        json {\n            source => \"[data][nats_message]\"\n            target => \"nats_message\"\n        }\n\n        mutate {\n            remove_field => \"[data][nats_message]\"\n        }\n    }\n\n    mutate {\n        add_tag => \"cloudfoundry_vcap\"\n        replace => [ \"[@shipper][priority]\", \"%{syslog_pri}\" ]\n        replace => [ \"[@shipper][name]\", \"%{[@shipper][name]}_%{[@metadata][type]}\" ]\n    }\n\n    mutate {\n        remove_field => \"syslog_facility\"\n        remove_field => \"syslog_facility_code\"\n        remove_field => \"syslog_message\"\n        remove_field => \"syslog_severity\"\n        remove_field => \"syslog_severity_code\"\n    }\n\n    mutate {\n        #replace => { \"[@metadata][index]\" => \"platform\" }\n        replace => { \"[@metadata][type]\" => \"%{[@metadata][type]}_cf\" }\n    }\n}\n\n}\n\n#Cleanup\nmutate {\n  rename => { \"[tags]\" => \"[@tags]\" }\n  remove_field => [ \"@version\" ]\n}\nif [@type] == \"NATS\" {\n  # Parse BOSH NATS logs \n  json {\n  \tsource => \"@message\"\n  \ttarget => \"NATS\"\n  }\n  \n  if [subject] {\n  \tmutate {\n  \t\trename => { \"[subject]\" => \"[NATS][subject]\" }\n  \t\trename => { \"[reply]\" => \"[NATS][reply]\" }\n  \t\tadd_field => { \"[@level]\" => \"INFO\" }\n  \t}\n  \t# When reply == nil rename doesn't remove it\n          mutate {\n  \t\tremove_field => \"[reply]\"\n  \t}\n  }\n  \n  if [NATS][subject] =~ /hm\\.agent\\.heartbeat.*/ {\n  \tmutate {\n  \t\tadd_field => { \"[@source][job_and_index]\" => \"%{[NATS][job]}/%{[NATS][index]}\" }\n  \t\tadd_tag => [\"hm_agent_heartbeat\"]\n  \t}\n  \tmutate {\n  \t\trename => { \"[NATS][job]\" => \"[@source][job]\" }\n  \t\trename => { \"[NATS][index]\" => \"[@source][index]\" }\n  \t}\n  \tmutate {\n  \t\tconvert => { \"[NATS][vitals][cpu][sys]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][cpu][user]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][cpu][wait]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][disk][ephemeral][inode_percent]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][disk][ephemeral][percent]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][disk][system][inode_percent]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][disk][system][percent]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][mem][kb]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][mem][percent]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][swap][kb]\" => \"float\" }\n  \t\tconvert => { \"[NATS][vitals][swap][percent]\" => \"float\" }\n  \t}\n  \tif [vitals][disk][persistent] {\n  \t\tmutate {\n  \t\t\tconvert => { \"[NATS][vitals][disk][persistent][inode_percent]\" => \"float\" }\n  \t\t\tconvert => { \"[NATS][vitals][disk][persistent][percent]\" => \"float\" }\n  \t\t}\n  \t}\n  \truby {\n  \t     code => \"event['NATS']['vitals']['load'] = { 'avg01' => event['NATS']['vitals']['load'][0].to_f, 'avg05' => event['NATS']['vitals']['load'][1].to_f, 'avg15' =>\\\n  event['NATS']['vitals']['load'][2].to_f }\"\n  \t}\n  } else if [NATS][subject] =~ /hm\\.(director|agent)\\.alert.*/ {\n  \tmutate {\n  \t\tadd_tag => \"hm_alert\"\n  \t}\n          date {\n  \t\tmatch => [ \"[NATS][created_at]\", \"UNIX\" ]\n  \t\ttag_on_failure => \"fail/NATS/hm_alert/date\"\n  \t\tremove_field => \"[NATS][created_at]\"\n  \t}\n  \ttranslate {\n  \t\tfield => \"[NATS][severity]\"\n  \t\tdestination => \"[@level]\"\n  \t\toverride => true\n  \t\tdictionary => [ \n  \t\t\t\"1\", \"FATAL\",\n  \t\t\t\"2\", \"FATAL\",\n  \t\t\t\"3\", \"ERROR\",\n  \t\t\t\"4\", \"WARN\" ]\n  \t\tfallback => \"INFO\"\n  \t}\n  }\n\n}\n"
  elasticsearch_config:
    <<: (( merge ))
    templates:
      - logsearch-for-cloudfoundry: "{\n  \"template\" : \"logs-*\",\n  \"order\": 50,\n  \"settings\" : {\n    \"index\" : {\n      \"codec\": \"best_compression\",\n      \"search\" : {\n        \"slowlog\" : {\n          \"threshold\" : {\n            \"query\" : {\n              \"warn\" : \"30s\",\n              \"info\" : \"15s\",\n              \"debug\" : \"10s\",\n              \"trace\" : \"5s\"\n            }\n          }\n        }\n      },\n      \"query\" : { \"default_field\" : \"@message\" }\n    }\n  },\n  \"mappings\" : {\n    \"_default_\" : {\n       \"_all\" : {\"enabled\" : false},\n       \"dynamic_templates\" : [ {\n         \"message_field\" : {\n           \"match\" : \"message\",\n           \"match_mapping_type\" : \"string\",\n           \"mapping\" : {\n             \"type\" : \"string\", \"index\" : \"analyzed\", \"omit_norms\" : true\n           }\n         }\n       }, {\n         \"string_fields\" : {\n           \"match\" : \"*\",\n           \"match_mapping_type\" : \"string\",\n           \"mapping\" : {\n             \"type\" : \"string\", \n             \"index\" : \"not_analyzed\", \n             \"omit_norms\" : true\n           }\n         }\n       } ],\n       \"properties\" : {\n         \"@version\": { \"type\": \"string\", \"index\": \"not_analyzed\" },\n         \"@message\" : {\n            \"type\" : \"string\",\n            \"index\" : \"analyzed\",\n            \"norms\" : { \"enabled\" : false }\n         },\n         \"geoip\"  : {\n           \"type\" : \"object\",\n             \"dynamic\": true,\n             \"properties\" : {\n               \"location\" : { \"type\" : \"geo_point\" }\n             }\n         }\n       }\n    }\n  }\n}\n\n" 
